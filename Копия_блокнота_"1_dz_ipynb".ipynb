{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fluorescentlightpower/mifi_homework/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%221_dz_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dee24c0-e9bf-427b-9b04-43e4c8220228",
      "metadata": {
        "id": "0dee24c0-e9bf-427b-9b04-43e4c8220228"
      },
      "source": [
        "# Домашнее задание"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feafcfd9-2d32-4682-bcd0-07a0c9bbd32c",
      "metadata": {
        "id": "feafcfd9-2d32-4682-bcd0-07a0c9bbd32c"
      },
      "source": [
        "Математический анализ\n",
        "69 баллов"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2345ed9-1018-4084-9636-7e7b92bd6c64",
      "metadata": {
        "id": "b2345ed9-1018-4084-9636-7e7b92bd6c64"
      },
      "source": [
        "**Задача 1** (14 баллов)\n",
        "\n",
        "Найдите экстремумы функции:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e25e75bf-9d1e-4511-8846-8bfe99ae17f8",
      "metadata": {
        "id": "e25e75bf-9d1e-4511-8846-8bfe99ae17f8"
      },
      "source": [
        "$$\n",
        "f(x, y, z)=2 x^3+2 x y+2 x z+y^2+z^2+2 y-8 .\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce92b07d-f19e-4f72-ab80-d04d0bae9984",
      "metadata": {
        "id": "ce92b07d-f19e-4f72-ab80-d04d0bae9984"
      },
      "source": [
        "Распишите подробное решение."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Исследование функции на экстремумы\n",
        "\n",
        "Рассмотрим функцию:\n",
        "$$\n",
        "f(x,y,z) = 2x^3 + 2xy + 2xz + y^2 + z^2 + 2y - 8\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "### 1) Частные производные первого порядка\n",
        "\n",
        "$$\n",
        "\\begin{cases}\n",
        "\\frac{\\partial f}{\\partial x} = 6x^2 + 2y + 2z,\\\\[4pt]\n",
        "\\frac{\\partial f}{\\partial y} = 2x + 2y + 2,\\\\[4pt]\n",
        "\\frac{\\partial f}{\\partial z} = 2x + 2z.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "### 2) Поиск стационарных точек\n",
        "\n",
        "Приравниваем совместно все частные производные к нулю:\n",
        "\n",
        "$$\n",
        "\\begin{cases}\n",
        "6x^2 + 2y + 2z = 0,\\\\[4pt]\n",
        "2x + 2y + 2 = 0,\\\\[4pt]\n",
        "2x + 2z = 0.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Из двух последних уравнений получаем:\n",
        "$$\n",
        "\\begin{cases}\n",
        "y = -x - 1,\\\\[4pt]\n",
        "z = -x.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Подставим это в первое уравнение:\n",
        "$$\n",
        "6x^2 + 2(-x - 1) + 2(-x) = 0\n",
        "\\Rightarrow 6x^2 - 4x - 2 = 0\n",
        "\\Rightarrow 3x^2 - 2x - 1 = 0.\n",
        "$$\n",
        "\n",
        "Корни квадратного уравнения по теореме Виета:\n",
        "$$\n",
        "\\left[\n",
        "\\begin{array}{1}\n",
        "x_1 = 1,\\\\[4pt]\n",
        "x_2 = -\\tfrac{1}{3}.\n",
        "\\end{array}\n",
        "\\right.\n",
        "$$\n",
        "\n",
        "Соответственно:\n",
        "$$\n",
        "\\left[\n",
        "\\begin{array}{1}\n",
        "x_1 = 1,\\; y_1 = -2,\\; z_1 = -1,\\\\[4pt]\n",
        "x_2 = -\\tfrac{1}{3},\\; y_2 = -\\tfrac{2}{3},\\; z_2 = \\tfrac{1}{3}.\n",
        "\\end{array}\n",
        "\\right.\n",
        "$$\n",
        "\n",
        "### 3) Вторые частные производные и гессиан\n",
        "Первая производная по $x$:\n",
        "$$\n",
        "\\frac{\\partial f}{\\partial x} = 6x^2 + 2y + 2z\n",
        "$$\n",
        "Частные производные второго порядка:\n",
        "$$\n",
        "\\frac{\\partial^2 f}{\\partial x^2} = 12x,\n",
        "\\qquad\n",
        "\\frac{\\partial^2 f}{\\partial x \\partial y} = 2,\n",
        "\\qquad\n",
        "\\frac{\\partial^2 f}{\\partial x \\partial z} = 2.\n",
        "$$\n",
        "\n",
        "Первая производная по $y$:\n",
        "$$\n",
        "\\frac{\\partial f}{\\partial y} = 2x + 2y + 2\n",
        "$$\n",
        "Отсюда с учетом независимости смешанных производных от порядка вычисления:\n",
        "$$\n",
        "\\frac{\\partial^2 f}{\\partial y^2} = 2,\n",
        "\\qquad\n",
        "\\frac{\\partial^2 f}{\\partial y \\partial z} = 0.\n",
        "$$\n",
        "\n",
        "Первая производная по $z$:\n",
        "$$\n",
        "\\frac{\\partial f}{\\partial z} = 2x + 2z\n",
        "$$\n",
        "Следовательно:\n",
        "$$\n",
        "\\frac{\\partial^2 f}{\\partial z^2} = 2,\n",
        "$$\n",
        "\n",
        "### 4) Матрица Гессе\n",
        "\n",
        "$$\n",
        "H =\n",
        "\\begin{pmatrix}\n",
        "\\frac{\\partial^2 f}{\\partial x^2} & \\frac{\\partial^2 f}{\\partial x \\partial y} & \\frac{\\partial^2 f}{\\partial x \\partial z}\\\\[6pt]\n",
        "\\frac{\\partial^2 f}{\\partial y \\partial x} & \\frac{\\partial^2 f}{\\partial y^2} & \\frac{\\partial^2 f}{\\partial y \\partial z}\\\\[6pt]\n",
        "\\frac{\\partial^2 f}{\\partial z \\partial x} & \\frac{\\partial^2 f}{\\partial z \\partial y} & \\frac{\\partial^2 f}{\\partial z^2}\n",
        "\\end{pmatrix}\n",
        "=\n",
        "\\begin{pmatrix}\n",
        "12x & 2 & 2\\\\\n",
        "2 & 2 & 0\\\\\n",
        "2 & 0 & 2\n",
        "\\end{pmatrix}.\n",
        "$$\n",
        "\n",
        "### 5) Анализ знака определителя (классификация стационарных точек)\n",
        "\n",
        "Для точки $(1,-2,-1)$:\n",
        "$$\n",
        "H(1)=\n",
        "\\begin{pmatrix}\n",
        "12 & 2 & 2\\\\\n",
        "2 & 2 & 0\\\\\n",
        "2 & 0 & 2\n",
        "\\end{pmatrix}, \\qquad\n",
        "\\Delta_1 = 12 > 0, \\quad\n",
        "\\Delta_2 =\n",
        "\\begin{vmatrix}\n",
        "12 & 2\\\\\n",
        "2 & 2\n",
        "\\end{vmatrix} = 12\\cdot2-2\\cdot2 = 20 > 0, \\quad\n",
        "$$\n",
        "\n",
        "Раскроем определитель по 3 столбцу:\n",
        "\n",
        "$$\n",
        "\\det H(1) =\n",
        "2\\begin{vmatrix}\n",
        "12 & 2\\\\\n",
        "2 & 2\n",
        "\\end{vmatrix}+\n",
        "2\\begin{vmatrix}\n",
        "2 & 2\\\\\n",
        "2 & 0\n",
        "\\end{vmatrix} = 40 + 2(-4)=\n",
        "32 > 0.\n",
        "$$\n",
        "\n",
        "Все угловые миноры положительны, матрица положительно определена.  \n",
        "Следовательно, $(1,-2,-1)$ — точка локального минимума.\n",
        "\n",
        "Для точки $\\left(-\\tfrac{1}{3},-\\tfrac{2}{3},\\tfrac{1}{3}\\right)$:\n",
        "$$\n",
        "H\\!\\left(-\\tfrac{1}{3}\\right) =\n",
        "\\begin{pmatrix}\n",
        "-4 & 2 & 2\\\\\n",
        "2 & 2 & 0\\\\\n",
        "2 & 0 & 2\n",
        "\\end{pmatrix}, \\qquad\n",
        "\\Delta_1 = -4<0, \\qquad\n",
        "\\begin{vmatrix}\n",
        "-4 & 2\\\\\n",
        "2 & 2\n",
        "\\end{vmatrix} = (-4)\\cdot2-2\\cdot2 = -12 < 0.\n",
        "$$\n",
        "\n",
        "Раскроем определитель по 3 столбцу:\n",
        "\n",
        "$$\n",
        "\\det H\\!\\left(-\\tfrac{1}{3}\\right) =\n",
        "2\\begin{vmatrix}\n",
        "-4 & 2\\\\\n",
        "2 & 2\n",
        "\\end{vmatrix}+\n",
        "2\\begin{vmatrix}\n",
        "2 & 2\\\\\n",
        "2 & 0\n",
        "\\end{vmatrix} = -24 + 2(-4)= -32 < 0.\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\det H\\!\\left(-\\tfrac{1}{3}\\right) = -32 < 0.\n",
        "$$\n",
        "\n",
        "Все угловые миноры отрицательны, матрица не определена, это седловая точка.\n",
        "\n",
        "### 6) Значение функции в точке минимума (экстремум)\n",
        "\n",
        "$$\n",
        "f(1,-2,-1) = 2(1)^3 + 2(1)(-2) + 2(1)(-1) + (-2)^2 + (-1)^2 + 2(-2) - 8 = -11,\n",
        "$$\n",
        "\n",
        "### 7) Глобальное поведение функции\n",
        "\n",
        "Так как в выражении присутствует кубический член $2x^3$,\n",
        "$$\n",
        "f(x,y,z) \\to +\\infty \\text{ при } x \\to +\\infty, \\qquad\n",
        "f(x,y,z) \\to -\\infty \\text{ при } x \\to -\\infty.\n",
        "$$\n",
        "функция не ограничена, глобальных экстремумов нет.\n",
        "\n",
        "### **Вывод**\n",
        "\n",
        "$$\n",
        "\\begin{cases}\n",
        "(1, -2, -1) &\\text{локальный минимум},\\\\[6pt]\n",
        "\\left(-\\tfrac{1}{3}, -\\tfrac{2}{3}, \\tfrac{1}{3}\\right) &\\text{седловая точка}\\\\[6pt]\n",
        "\\end{cases}\n",
        "$$\n",
        "Глобальных экстремумов нет. В точке локального минимума функция принимает значение $f(1, -2, -1)=-11$"
      ],
      "metadata": {
        "id": "2QZ03fyor5Bg"
      },
      "id": "2QZ03fyor5Bg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eddb54d-58f6-47ed-bef4-cb262d500cbe",
      "metadata": {
        "id": "0eddb54d-58f6-47ed-bef4-cb262d500cbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b23a32f-0c25-4ffb-f63a-4c81251ef1f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Минимум\n",
            "-11.0\n",
            "Точка минимума\n",
            "[ 1.         -1.99999998 -1.00000001]\n",
            "          message: `xtol` termination condition is satisfied.\n",
            "          success: True\n",
            "           status: 2\n",
            "              fun: -11.0\n",
            "                x: [ 1.000e+00 -2.000e+00 -1.000e+00]\n",
            "              nit: 55\n",
            "             nfev: 196\n",
            "             njev: 49\n",
            "             nhev: 0\n",
            "         cg_niter: 106\n",
            "     cg_stop_cond: 2\n",
            "             grad: [ 1.192e-07 -0.000e+00 -1.192e-07]\n",
            "  lagrangian_grad: [ 1.192e-07 -0.000e+00 -1.192e-07]\n",
            "           constr: []\n",
            "              jac: []\n",
            "      constr_nfev: []\n",
            "      constr_njev: []\n",
            "      constr_nhev: []\n",
            "                v: []\n",
            "           method: equality_constrained_sqp\n",
            "       optimality: 1.1920928866260283e-07\n",
            " constr_violation: 0\n",
            "   execution_time: 0.09179973602294922\n",
            "        tr_radius: 6.582883364746276e-09\n",
            "   constr_penalty: 1.0\n",
            "            niter: 55\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "tfunc = lambda x: 2 * x[0]**3 + 2 * x[0] * x[1] + 2 * x[0] * x[2] + x[1]**2 + x[2]**2 + 2 * x[1] - 8\n",
        "# tfunc_m = lambda x: -4 * x[0] - 8 * x[1]\n",
        "# cons = ({'type': 'eq', 'fun': lambda x: x[1]**2 - 2 * x[0] * x[1] + 5})\n",
        "res_min = minimize(tfunc, (-0.33, -0.66, 0.33), method='trust-constr') #, constraints=cons)\n",
        "# res_max = minimize(tfunc_m, (-1, -1), method='trust-constr', constraints=cons)\n",
        "print('Минимум', res_min.fun, 'Точка минимума', res_min.x, sep='\\n')\n",
        "# print('Максимум', res_max.fun, 'Точка максимума', res_max.x, sep='\\n')\n",
        "print(res_min)\n",
        "# print(res_max)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b38584b7-0da5-4858-9422-ff5bc2b3854f",
      "metadata": {
        "id": "b38584b7-0da5-4858-9422-ff5bc2b3854f"
      },
      "source": [
        "**Задача 2** (25 баллов)\n",
        "\n",
        "Найдите условные экстремумы функции:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b36ed820-965b-484d-baab-b2cafebe7479",
      "metadata": {
        "id": "b36ed820-965b-484d-baab-b2cafebe7479"
      },
      "source": [
        "$$\n",
        "f(x, y)=4 x+8 y, y^2-2 x y+5=0\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ce1c6f1-d126-4368-a63e-2bbbefffd542",
      "metadata": {
        "id": "2ce1c6f1-d126-4368-a63e-2bbbefffd542"
      },
      "source": [
        "Вычислите результат самостоятельно (вручную) и с помощью Python. Сравните результаты."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Поиск условных экстремумов для\n",
        "\n",
        "$f(x,y) = 4x + 8y$ при ограничении $g(x,y)=y^2 - 2xy + 5 = 0$\n",
        "\n",
        "## 1. Функция Лагранжа\n",
        "\n",
        "$$\n",
        "L(x,y,\\lambda) = f(x,y) + \\lambda \\, g(x,y)\n",
        "= 4x + 8y + \\lambda (y^2 - 2xy + 5).\n",
        "$$\n",
        "\n",
        "## 2. Условия первого порядка\n",
        "\n",
        "Необходимо найти стационарные точки функции Лагранжа по переменным $x, y, \\lambda$.\n",
        "Для этого приравниваем к нулю частные производные:\n",
        "\n",
        "1. По $x$:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial x}\n",
        "= 4 - 2\\lambda y = 0.\n",
        "$$\n",
        "Отсюда\n",
        "$$\n",
        "4 - 2\\lambda y = 0 \\quad \\Longrightarrow \\quad \\lambda y = 2.\n",
        "$$\n",
        "\n",
        "2. По $y$:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial y}\n",
        "= 8 + \\lambda (2y - 2x)\n",
        "= 0.\n",
        "$$\n",
        "То есть\n",
        "$$\n",
        "8 + \\lambda (2y - 2x) = 0\n",
        "\\quad \\Longrightarrow \\quad\n",
        "\\lambda (y - x) = -4.\n",
        "$$\n",
        "\n",
        "3. По $\\lambda$:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial \\lambda} = y^2 - 2xy + 5 = 0.\n",
        "$$\n",
        "\n",
        "Таким образом, получаем систему:\n",
        "$$\n",
        "\\begin{cases}\n",
        "\\lambda y = 2, \\\\\n",
        "\\lambda (y - x) = -4, \\\\\n",
        "y^2 - 2xy + 5 = 0.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "## 3. Выражение $\\lambda$ и связь между $x$ и $y$\n",
        "\n",
        "Из первого уравнения:\n",
        "$$\n",
        "\\lambda = \\frac{2}{y}, \\quad y \\ne 0.\n",
        "$$\n",
        "\n",
        "Подставим во второе уравнение:\n",
        "$$\n",
        "\\frac{2}{y}(y - x) = -4\n",
        "\\quad \\Longrightarrow \\quad\n",
        "2 \\cdot \\frac{y - x}{y} = -4\n",
        "\\quad \\Longrightarrow \\quad\n",
        "\\frac{y - x}{y} = -2\n",
        "\\quad \\Longrightarrow \\quad\n",
        "y - x = -2y\n",
        "\\quad \\Longrightarrow \\quad\n",
        "x = 3y.\n",
        "$$\n",
        "\n",
        "## 4. Подстановка в ограничение\n",
        "$$\n",
        "y^2 - 2\\cdot(3y)\\cdot y + 5 = 0\n",
        "\\quad \\Longrightarrow \\quad\n",
        "y^2 - 6y^2 + 5 = 0\n",
        "\\quad \\Longrightarrow \\quad\n",
        "-5y^2 + 5 = 0\n",
        "\\quad \\Longrightarrow \\quad\n",
        "y^2 = 1.\n",
        "$$\n",
        "\n",
        "Отсюда\n",
        "$$\n",
        "y = \\pm 1.\n",
        "$$\n",
        "\n",
        "Тогда\n",
        "$$\n",
        "x = 3y,  \\quad \\lambda = \\frac{2}{y} \\quad \\Longrightarrow \\quad\n",
        "\\left[\n",
        "\\begin{array}{1}\n",
        "y = 1 \\Rightarrow x = 3, \\quad \\lambda = 2\\\\\n",
        "y = -1 \\Rightarrow x = -3, \\quad \\lambda = -2.\n",
        "\\end{array}\n",
        "\\right.\n",
        "$$\n",
        "\n",
        "Кандидаты на точки условного экстремума:\n",
        "$$\n",
        "( x, y ) = (3, 1), \\quad ( x, y ) = (-3, -1).\n",
        "$$\n",
        "\n",
        "## 5. Значения функции в найденных точках\n",
        "\n",
        "$$\n",
        "f(3, 1) = 4 \\cdot 3 + 8 \\cdot 1 = 12 + 8 = 20,\n",
        "$$\n",
        "$$\n",
        "f(-3, -1) = 4 \\cdot (-3) + 8 \\cdot (-1) = -12 - 8 = -20.\n",
        "$$\n",
        "\n",
        "То есть:\n",
        "- в точке $(3,1)$ функция принимает значение $20$;\n",
        "- в точке $(-3,-1)$ функция принимает значение $-20$.\n",
        "\n",
        "## 6. Гессиан\n",
        "\n",
        "Вторые производные:\n",
        "$$\n",
        "\\frac{\\partial^2 L}{\\partial x^2} = 0, \\quad\n",
        "\\frac{\\partial^2 L}{\\partial x \\partial y} = -2\\lambda, \\quad\n",
        "\\frac{\\partial^2 L}{\\partial y \\partial x} = -2\\lambda, \\quad\n",
        "\\frac{\\partial^2 L}{\\partial y^2} = 2\\lambda.\n",
        "$$\n",
        "\n",
        "Матрица Гессе по $x, y$:\n",
        "$$\n",
        "H_L(x,y,\\lambda) =\n",
        "\\begin{pmatrix}\n",
        "0 & -2\\lambda \\\\\n",
        "-2\\lambda & 2\\lambda\n",
        "\\end{pmatrix}.\n",
        "$$\n",
        "\n",
        "Угловой минор $\\Delta_1\\equiv0$ $\\forall x,y,λ$. Критерий Сильвестра требует строгого неравенства угловых миноров нулю для утверждения о знакоопределенности квадратичной формы, поэтому гессиан без учета ограничения $g(x,y)$ не является знакоопределенным.\n",
        "\n",
        "Запишем второй дифференциал функции Лагранжа в виде квадратичной формы по $dx$ и $dy$:\n",
        "\n",
        "$$\n",
        "d^2L=\\left(\\frac{\\partial}{\\partial x}dx + \\frac{\\partial}{\\partial }dy + \\frac{\\partial}{\\partial z}dz\\right)^2L = \\frac{\\partial^2 L}{\\partial x^2}dx^2 + 2\\frac{\\partial^2 L}{\\partial x \\partial y}dxdy + \\frac{\\partial^2 L}{\\partial y^2}dy^2 = -2\\lambda dxdy + 2\\lambda dy^2\n",
        "$$\n",
        "\n",
        "Исследуемая исходная функция зависит от 2 переменных $n=2$, и условный экстремум ищется при одном наложенном условии $m=1$. Следовательно, градиент наложенного условия $g(x,y)$ для поиска экстремума имеет $k=n-m=1$ независимую переменную из $dx$ и $dy$ (см. В. А. Зорич. Математический анализ. Часть I, с. 494)\n",
        "\n",
        "$$\n",
        "\\nabla g(x,y) = \\left( \\frac{\\partial g}{\\partial x}, \\frac{\\partial g}{\\partial y} \\right)\n",
        "= (-2y, \\, 2y - 2x).\n",
        "$$\n",
        "\n",
        "Касательный вектор градиента к поверхности ограничения должен удовлетворять условию\n",
        "$$\n",
        "\\nabla g(x,y) \\cdot (dx, dy) = 0\n",
        "\\quad \\Longrightarrow \\quad\n",
        "-2y \\, dx + (2y-2x) \\, dy = 0\n",
        "\\quad \\Longrightarrow \\quad\n",
        "y \\, dx = (y-x) \\, dy\n",
        "\\quad \\Longrightarrow \\quad\n",
        "dx = \\frac{y-x}{y} \\, dy.\n",
        "$$\n",
        "\n",
        "Подставим $dx$ в выражение второго дифференциала функции Лагранжа\n",
        "\n",
        "$$\n",
        "d^2L(x,y,\\lambda)=-2\\lambda \\frac{y-x}{y} \\, dy^2 + 2\\lambda \\, dy^2 = -2\\lambda \\left(\\frac{y-x}{y} \\, dy^2 - dy^2 \\right) = -2\\lambda \\frac{y-x-y}{y} \\, dy^2 = 2\\lambda \\frac{x}{y} \\, dy^2\n",
        "$$\n",
        "\n",
        "В точке $(3,1)$ и при $\\lambda = 2$ второй дифференциал функции Лагранжа принимает вид:\n",
        "\n",
        "$$\n",
        "d^2L(3,1,2) = 4\\cdot\\frac{3}{1} \\, dy^2 = 12 \\, dy^2 > 0 \\quad \\forall dy\n",
        "$$\n",
        "\n",
        "Второй дифференциал в точке положительно определен, следовательно, это точка условного локального минимума\n",
        "\n",
        "В точке $(-3,-1)$ и $\\lambda = -2$:\n",
        "\n",
        "$$\n",
        "d^2L(-3,-1,-2) = (-4)\\cdot\\frac{(-3)}{(-1)} \\, dy^2 = -12 \\, dy^2 < 0 \\quad \\forall dy\n",
        "$$\n",
        "\n",
        "Второй дифференциал в точке отрицательно определен, следовательно, это точка условного локального максимума\n",
        "\n",
        "## 7. Вывод\n",
        "\n",
        "- Условный минимум:\n",
        "$$\n",
        "f_{\\min} = 20 \\quad \\text{в точке} \\quad (x,y) = (3,1).\n",
        "$$\n",
        "\n",
        "- Условный максимум:\n",
        "$$\n",
        "f_{\\max} = -20 \\quad \\text{в точке} \\quad (x,y) = (-3,-1).\n",
        "$$\n"
      ],
      "metadata": {
        "id": "Vrtw_D8A-79W"
      },
      "id": "Vrtw_D8A-79W"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверка с помощью Python"
      ],
      "metadata": {
        "id": "l0cFjnzA4rPr"
      },
      "id": "l0cFjnzA4rPr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "818929f6-c478-49ad-997e-536d3c4f7f33",
      "metadata": {
        "id": "818929f6-c478-49ad-997e-536d3c4f7f33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6d1677e-0f53-4e00-a1da-b0960751b02c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Минимум\n",
            "20.0\n",
            "Точка минимума\n",
            "[3. 1.]\n",
            "Максимум\n",
            "-20.0\n",
            "Точка максимума\n",
            "[-3. -1.]\n",
            "\n",
            "\n",
            "Данные вычислений для минимума\n",
            "          message: `xtol` termination condition is satisfied.\n",
            "          success: True\n",
            "           status: 2\n",
            "              fun: 20.0\n",
            "                x: [ 3.000e+00  1.000e+00]\n",
            "              nit: 20\n",
            "             nfev: 48\n",
            "             njev: 16\n",
            "             nhev: 0\n",
            "         cg_niter: 19\n",
            "     cg_stop_cond: 1\n",
            "             grad: [ 4.000e+00  8.000e+00]\n",
            "  lagrangian_grad: [-4.768e-08  2.384e-08]\n",
            "           constr: [array([ 0.000e+00])]\n",
            "              jac: [array([[-2.000e+00, -4.000e+00]])]\n",
            "      constr_nfev: [48]\n",
            "      constr_njev: [0]\n",
            "      constr_nhev: [0]\n",
            "                v: [array([ 2.000e+00])]\n",
            "           method: equality_constrained_sqp\n",
            "       optimality: 4.7683716530855236e-08\n",
            " constr_violation: 0.0\n",
            "   execution_time: 0.046157121658325195\n",
            "        tr_radius: 9.347124626157249e-09\n",
            "   constr_penalty: 8.085879584115297\n",
            "            niter: 20\n",
            "\n",
            "\n",
            "Данные вычислений для максимума\n",
            "          message: `xtol` termination condition is satisfied.\n",
            "          success: True\n",
            "           status: 2\n",
            "              fun: 20.0\n",
            "                x: [-3.000e+00 -1.000e+00]\n",
            "              nit: 20\n",
            "             nfev: 48\n",
            "             njev: 16\n",
            "             nhev: 0\n",
            "         cg_niter: 19\n",
            "     cg_stop_cond: 1\n",
            "             grad: [-4.000e+00 -8.000e+00]\n",
            "  lagrangian_grad: [ 4.768e-08 -2.384e-08]\n",
            "           constr: [array([ 0.000e+00])]\n",
            "              jac: [array([[ 2.000e+00,  4.000e+00]])]\n",
            "      constr_nfev: [48]\n",
            "      constr_njev: [0]\n",
            "      constr_nhev: [0]\n",
            "                v: [array([ 2.000e+00])]\n",
            "           method: equality_constrained_sqp\n",
            "       optimality: 4.7683716530855236e-08\n",
            " constr_violation: 0.0\n",
            "   execution_time: 0.03205561637878418\n",
            "        tr_radius: 9.347124626157249e-09\n",
            "   constr_penalty: 8.085879584115297\n",
            "            niter: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/optimize/_differentiable_functions.py:376: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
            "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "tfunc = lambda x: 4 * x[0] + 8 * x[1]\n",
        "tfunc_m = lambda x: -4 * x[0] - 8 * x[1]\n",
        "cons = ({'type': 'eq', 'fun': lambda x: x[1]**2 - 2 * x[0] * x[1] + 5})\n",
        "res_min = minimize(tfunc, (1, 1), method='trust-constr', constraints=cons)\n",
        "res_max = minimize(tfunc_m, (-1, -1), method='trust-constr', constraints=cons)\n",
        "print('Минимум', res_min.fun, 'Точка минимума', res_min.x, sep='\\n')\n",
        "print('Максимум', -res_max.fun, 'Точка максимума', res_max.x, '\\n', sep='\\n')\n",
        "print('Данные вычислений для минимума', res_min, '\\n', sep='\\n')\n",
        "print('Данные вычислений для максимума', res_max, sep='\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Метод minimize из библиотеки scipy находит те же точки $(3,1)$ и $(-3,-1)$ как точки условного локального минимума и условного локального максимума соответственно. Условные экстремумы также составляют -20 и 20 для минимума и максимума соответственно."
      ],
      "metadata": {
        "id": "eFQSP_vfucst"
      },
      "id": "eFQSP_vfucst"
    },
    {
      "cell_type": "markdown",
      "id": "818083c3-7318-4669-bb15-5a8a48ef543d",
      "metadata": {
        "id": "818083c3-7318-4669-bb15-5a8a48ef543d"
      },
      "source": [
        "**Задача 3** (30 баллов)\n",
        "\n",
        "Вам предложены данные с информацией о успеваемости студентов:\n",
        "\n",
        "Независимые переменные:\n",
        "* Hours Studied: Общее количество часов, потраченных на учебу каждым студентом.\n",
        "* Previous Scores: Баллы, полученные студентами на предыдущих экзаменах.\n",
        "* Sleep Hours: Среднее количество часов сна студента в сутки.\n",
        "* Sample Question Papers Practiced: Количество пробных экзаменационных работ, с которыми студент занимался.\n",
        "  \n",
        "Целевая переменная:\n",
        "* Performance Index: Показатель общей успеваемости каждого студента. Индекс успеваемости отражает академическую успеваемость студента и округляется до ближайшего целого числа. Индекс варьируется от 10 до 100, при этом более высокие значения свидетельствуют о более высокой успеваемости."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f65c2300-43b2-4c43-b762-1e20d29ae889",
      "metadata": {
        "id": "f65c2300-43b2-4c43-b762-1e20d29ae889"
      },
      "source": [
        "**Решите задачу линейной регрессии, реализовав градиентный спуск самостоятельно, не используя готовое решение из какой-либо библиотеки.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Постановка задачи линейной регрессии\n",
        "\n",
        "Пусть дана выборка из $m$ наблюдений:\n",
        "$$\n",
        "D = \\{(x^{(i)}, y^{(i)})\\}_{i=1}^{m},\n",
        "$$\n",
        "где $x^{(i)} = (x^{(i)}_1, x^{(i)}_2, \\dots, x^{(i)}_n)^T \\in \\mathbb{R}^n$ — вектор признаков $i$-го объекта,\n",
        "а $y^{(i)} \\in \\mathbb{R}$ — соответствующее значение целевой переменной.\n",
        "\n",
        "Требуется найти такую линейную зависимость между признаками и откликом, которая наилучшим образом описывает наблюдаемые данные:\n",
        "$$\n",
        "\\hat{y}^{(i)} = w_0 + w_1 x^{(i)}_1 + w_2 x^{(i)}_2 + \\dots + w_n x^{(i)}_n = w_0 + \\mathbf{w}^T \\mathbf{x}^{(i)},\n",
        "$$\n",
        "где $w_0 \\in \\mathbb{R}$ — свободный член (смещение), $\\mathbf{w} = (w_1, w_2, \\dots, w_n)^T$ — вектор коэффициентов регрессии (веса).\n",
        "\n",
        "Требуется подобрать веса $\\mathbf{w}$ и $w_0$, минимизирующие среднеквадратичную ошибку (MSE) между предсказанными и истинными значениями:\n",
        "$$\n",
        "MSE = \\frac{1}{m} \\sum_{i=1}^{m} \\left( y^{(i)} - (w_0 + \\mathbf{w}^T \\mathbf{x}^{(i)}) \\right)^2.\n",
        "$$\n",
        "\n",
        "В матричной форме модель можно записать:\n",
        "$$\n",
        "\\hat{\\mathbf{y}} = X \\mathbf{w},\n",
        "$$\n",
        "где $X \\in \\mathbb{R}^{m \\times n}$ — матрица признаков,\n",
        "$\\mathbf{y} \\in \\mathbb{R}^{m}$ — вектор целевых значений,\n",
        "а функция потерь имеет вид:\n",
        "$$\n",
        "MSE = \\frac{1}{m} (\\mathbf{y} - X\\mathbf{w})^T (\\mathbf{y} - X\\mathbf{w}).\n",
        "$$\n",
        "\n",
        "Минимум функции и веса требуется найти с помощью метода градиентного спуска. Целевым вектором $\\mathbf{y}$ будет Performance Index - последняя колонка из файла. Признаками в матрице $X$ будут остальные столбцы, кроме третьего с бинарным признаком Yes/No. Также добавим вручную столбец из единиц в качестве первого к матрице $X$, чтобы учесть смещение в распределении исходных данных\n"
      ],
      "metadata": {
        "id": "tBtfI0WmKd-w"
      },
      "id": "tBtfI0WmKd-w"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "3900c065-fb9b-45bf-bc1f-a9c9d0ab5c20",
      "metadata": {
        "id": "3900c065-fb9b-45bf-bc1f-a9c9d0ab5c20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e9b9c5a-f73a-4ea1-8dd6-23f6a4bff6e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Шаг: 1000, MSE: 0.0913154960689881\n",
            "Шаг: 2000, MSE: 0.0701229722860615\n",
            "Шаг: 3000, MSE: 0.056381635692872266\n",
            "Шаг: 4000, MSE: 0.04603875221300473\n",
            "Шаг: 5000, MSE: 0.03821707156035765\n",
            "Шаг: 6000, MSE: 0.032277593635348434\n",
            "Шаг: 7000, MSE: 0.027748238571611496\n",
            "Шаг: 8000, MSE: 0.02427912437262829\n",
            "Шаг: 9000, MSE: 0.021610099112924292\n",
            "Шаг: 10000, MSE: 0.019547093354619318\n",
            "Шаг: 11000, MSE: 0.01794485141443334\n",
            "Шаг: 12000, MSE: 0.01669428641463667\n",
            "Шаг: 13000, MSE: 0.015713194960639023\n",
            "Шаг: 14000, MSE: 0.01493941903572787\n",
            "Шаг: 15000, MSE: 0.014325795159707295\n",
            "Шаг: 16000, MSE: 0.01383641237524387\n",
            "Шаг: 17000, MSE: 0.013443831386847674\n",
            "Шаг: 18000, MSE: 0.013127011566861089\n",
            "Шаг: 19000, MSE: 0.012869760824644015\n",
            "Шаг: 20000, MSE: 0.012659572843218777\n",
            "Шаг: 21000, MSE: 0.012486752169768666\n",
            "Шаг: 22000, MSE: 0.012343753863560106\n",
            "Шаг: 23000, MSE: 0.012224683557018851\n",
            "Шаг: 24000, MSE: 0.012124917814589464\n",
            "Шаг: 25000, MSE: 0.01204081497878927\n",
            "Шаг: 26000, MSE: 0.01196949428378795\n",
            "Шаг: 27000, MSE: 0.011908666624921934\n",
            "Шаг: 28000, MSE: 0.011856504527985102\n",
            "Шаг: 29000, MSE: 0.011811541950377064\n",
            "Шаг: 30000, MSE: 0.011772596848176416\n",
            "Шаг: 31000, MSE: 0.011738711164237815\n",
            "Шаг: 32000, MSE: 0.011709104182910485\n",
            "Шаг: 33000, MSE: 0.011683136167476424\n",
            "Шаг: 34000, MSE: 0.011660279928352927\n",
            "Шаг: 35000, MSE: 0.011640098523685336\n",
            "Шаг: 36000, MSE: 0.011622227713785809\n",
            "Шаг: 37000, MSE: 0.01160636211011363\n",
            "Шаг: 38000, MSE: 0.011592244202869301\n",
            "Шаг: 39000, MSE: 0.011579655637277546\n",
            "Шаг: 40000, MSE: 0.011568410251129823\n",
            "Шаг: 41000, MSE: 0.011558348495573965\n",
            "Шаг: 42000, MSE: 0.011549332945343526\n",
            "Шаг: 43000, MSE: 0.011541244669560944\n",
            "Шаг: 44000, MSE: 0.01153398028443796\n",
            "Шаг: 45000, MSE: 0.011527449548063637\n",
            "Шаг: 46000, MSE: 0.011521573387628794\n",
            "Шаг: 47000, MSE: 0.011516282272881815\n",
            "Шаг: 48000, MSE: 0.011511514867874422\n",
            "Шаг: 49000, MSE: 0.011507216907309471\n",
            "Шаг: 50000, MSE: 0.01150334025494852\n",
            "Коэффициенты:/n [[0.35739918]\n",
            " [4.30501507]\n",
            " [1.54527547]\n",
            " [0.63096311]\n",
            " [0.28109578]]\n",
            "MSE: 18386.653602647613\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Открытие файла с сайта\n",
        "url = \"https://lms.skillfactory.ru/asset-v1:skillfactory+MIFIML-1sem+2025+type@asset+block@%D0%9C%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B8__%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7_%D0%B8_%D1%82%D0%B5%D0%BE%D1%80%D0%B8%D1%8F_%D0%B2%D0%B5%D1%80%D0%BE%D1%8F%D1%82%D0%BD%D0%BE%D1%81%D1%82%D0%B5%D0%B8_._%D0%94%D0%97_1._%D0%94%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5_%D0%BF%D0%BE_%D0%B7%D0%B0%D0%B4%D0%B0%D0%BD%D0%B8%D1%8E_3.txt\"\n",
        "df = pd.read_csv(url)\n",
        "X = df.drop(columns=['Performance Index', 'Extracurricular Activities']) # Убираем лишние колонки\n",
        "y = df['Performance Index']  # Столбец целевой переменной с преобразованием к вектору\n",
        "\n",
        "# Отбор произвольных строк из файла. Они не будут использоваться для построения модели, но нужны для проверки. Тестовая выборка.\n",
        "test_range = np.arange(5000, 5100)\n",
        "X_Smpl = X.loc[test_range].to_numpy()\n",
        "y_Smpl = y.loc[test_range].to_numpy().reshape(-1, 1)\n",
        "X = X.drop(index=test_range).to_numpy()\n",
        "y = y.drop(index=test_range)\n",
        "\n",
        "y = y.to_numpy().reshape(-1, 1)\n",
        "\n",
        "# Стандартизация и добавление вектора смещения как столбца из единиц\n",
        "X = (X - X.mean()) / X.std()\n",
        "X = np.c_[np.ones((X.shape[0], 1)), X]\n",
        "X_Smpl = np.c_[np.ones((X_Smpl.shape[0], 1)), X_Smpl]\n",
        "y = (y - y.mean()) / y.std()\n",
        "y_Smpl = (y_Smpl - y_Smpl.mean()) / y_Smpl.std()\n",
        "\n",
        "# Инициализация\n",
        "y_len = y.shape[0]\n",
        "w = np.zeros((X.shape[1], 1))\n",
        "alpha = 0.01\n",
        "n=0\n",
        "\n",
        "def loss_f (y, y_pr):\n",
        "    return np.mean((y - y_pr)**2)\n",
        "\n",
        "while n<50000:\n",
        "    y_pr = X @ w    # Предсказание на каждом шаге градиентного спуска\n",
        "    grad = -2 / y_len * X.T @ (y - y_pr)    # Градиент на шаге\n",
        "    w -= alpha * grad   # Обновление весов\n",
        "    n += 1\n",
        "    if n % 1000 == 0:\n",
        "        delta = loss_f (y, y_pr) # MSE на шаге\n",
        "        print(f\"Шаг: {n}, MSE: {delta}\")\n",
        "print('Коэффициенты:/n', w)\n",
        "y_prS = X_Smpl @ w\n",
        "print('MSE:', loss_f(y_Smpl, y_prS))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Точное решение для линейной регрессии:"
      ],
      "metadata": {
        "id": "YFOuvBxwkaRW"
      },
      "id": "YFOuvBxwkaRW"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "model = LinearRegression(fit_intercept=False) # Уже есть смещение в матрице признаков, нужно отключить встроенный в sklearn\n",
        "model.fit(X, y)\n",
        "y_pred = model.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "print('Коэффициенты:\\n', model.coef_.T)\n",
        "print('MSE:',mse)\n",
        "y_pred1 = model.predict(X_Smpl)\n",
        "mse1 = mean_squared_error(y_Smpl, y_pred1)\n",
        "print('MSE для тестовой выборки:',mse1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "655ma4mrdTSg",
        "outputId": "f1dd21d0-a181-4ef1-bf19-1e2a6cea748b"
      },
      "id": "655ma4mrdTSg",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Коэффициенты:\n",
            " [[0.42806754]\n",
            " [4.32728348]\n",
            " [1.54437586]\n",
            " [0.72472406]\n",
            " [0.29619442]]\n",
            "MSE: 0.011466924491874537\n",
            "MSE для тестовой выборки: 18598.18891840718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Инициализация и обучение\n",
        "model = SGDRegressor(\n",
        "    max_iter=1000,       # количество итераций\n",
        "    eta0=0.01,           # шаг обучения (learning rate)\n",
        "    learning_rate='constant',  # фиксированный шаг\n",
        "    penalty=None,        # без регуляризации\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X, y.ravel())\n",
        "\n",
        "# Результаты\n",
        "print('Коэффициенты:', model.coef_)\n",
        "print('MSE:', mean_squared_error(y, model.predict(X)))\n",
        "print('MSE для тестовой выборки:', mean_squared_error(y_Smpl, model.predict(X_Smpl)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhwVHp1QjEss",
        "outputId": "27773ed8-a752-4124-9efb-aecfcad7c6b4"
      },
      "id": "BhwVHp1QjEss",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Коэффициенты: [0.18378397 4.3081392  1.55653187 0.6476702  0.28877714]\n",
            "MSE: 0.01173430264920762\n",
            "MSE для тестовой выборки: 18645.12289413659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализованный вручную градиентный спуск дает очень близкие значения для весов линейной регрессии, что и метод стохастического градиентного спуска из библиотеки sklearn. Отличие заметно только в смещении, но MSE для тестовой выборки очень близки."
      ],
      "metadata": {
        "id": "CZgAKeqSBSZd"
      },
      "id": "CZgAKeqSBSZd"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}